#!/usr/bin/env python3
"""
Scraper ultime pour le Barreau de Thonon
Utilise la bonne URL avec pagination correcte
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import json
import csv
from datetime import datetime
import re

class ThononUltimateScraper:
    def __init__(self):
        self.base_url = "https://public.barreau-thonon.fr/lannuaire/"
        self.lawyers = {}
        self.setup_driver()
    
    def setup_driver(self):
        """Configuration du driver Selenium"""
        options = webdriver.ChromeOptions()
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"]) 
        options.add_experimental_option('useAutomationExtension', False)
        # Mode visible pour debug
        # options.add_argument('--headless')
        
        self.driver = webdriver.Chrome(options=options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    
    def extract_lawyer_from_listing(self, listing):
        """Extrait les infos d'un avocat depuis un Ã©lÃ©ment listing"""
        try:
            lawyer = {
                'name': '',
                'address': '',
                'phone': '',
                'fax': '',
                'email': '',
                'specialities': []
            }
            
            # Nom - dans le titre
            title = listing.find_elements(By.CSS_SELECTOR, '.wpbdp-field-name, .listing-title, h2')
            if title:
                lawyer['name'] = title[0].text.strip()
            
            # Adresse
            address_elem = listing.find_elements(By.CSS_SELECTOR, '.wpbdp-field-adresse, .address, .wpbdp-field-address')
            if address_elem:
                lawyer['address'] = address_elem[0].text.strip()
            
            # TÃ©lÃ©phone
            phone_elem = listing.find_elements(By.CSS_SELECTOR, '.wpbdp-field-tel, .wpbdp-field-telephone, .phone')
            if phone_elem:
                lawyer['phone'] = phone_elem[0].text.replace('Tel:', '').strip()
            
            # Fax
            fax_elem = listing.find_elements(By.CSS_SELECTOR, '.wpbdp-field-fax')
            if fax_elem:
                lawyer['fax'] = fax_elem[0].text.replace('Fax:', '').strip()
            
            # Email - chercher les liens mailto
            email_links = listing.find_elements(By.CSS_SELECTOR, 'a[href^="mailto:"]')
            if email_links:
                lawyer['email'] = email_links[0].get_attribute('href').replace('mailto:', '')
            
            # SpÃ©cialitÃ©s
            spec_elem = listing.find_elements(By.CSS_SELECTOR, '.wpbdp-field-specialites, .specialities, .wpbdp-field-specialite')
            if spec_elem:
                lawyer['specialities'] = [s.strip() for s in spec_elem[0].text.split(',')]
            
            # Si pas de nom trouvÃ©, utiliser le texte complet
            if not lawyer['name']:
                full_text = listing.text.strip()
                lines = full_text.split('\n')
                if lines:
                    # PremiÃ¨re ligne non vide est probablement le nom
                    for line in lines:
                        if line.strip() and not line.startswith('Tel:') and not line.startswith('Fax:'):
                            lawyer['name'] = line.strip()
                            break
            
            return lawyer
            
        except Exception as e:
            print(f"    [!] Erreur extraction: {e}")
            return None
    
    def extract_page(self, page_num):
        """Extrait les avocats d'une page spÃ©cifique"""
        url = f"https://public.barreau-thonon.fr/lannuaire/page/{page_num}/?wpbdp_view=all_listings"
        
        print(f"\nğŸ“„ Page {page_num}")
        print(f"   URL: {url}")
        
        self.driver.get(url)
        time.sleep(2)  # Attendre le chargement
        
        # Chercher les listings
        listings = self.driver.find_elements(By.CSS_SELECTOR, '.wpbdp-listing')
        
        if not listings:
            print(f"   [x] Aucun avocat trouvÃ©")
            return 0
        
        print(f"   [âœ“] {len(listings)} avocats trouvÃ©s")
        
        new_count = 0
        for listing in listings:
            lawyer = self.extract_lawyer_from_listing(listing)
            if lawyer and lawyer['name']:
                # ClÃ© unique basÃ©e sur le nom
                key = lawyer['name'].lower().replace(' ', '_')
                if key not in self.lawyers:
                    self.lawyers[key] = lawyer
                    new_count += 1
                    print(f"      + {lawyer['name']}")
        
        print(f"   â†’ {new_count} nouveaux avocats ajoutÃ©s")
        return new_count
    
    def find_total_pages(self):
        """Trouve le nombre total de pages"""
        print("\nğŸ” Recherche du nombre total de pages...")
        
        # Aller Ã  la premiÃ¨re page avec all_listings
        self.driver.get("https://public.barreau-thonon.fr/lannuaire/?wpbdp_view=all_listings")
        time.sleep(2)
        
        # Chercher la pagination
        pagination = self.driver.find_elements(By.CSS_SELECTOR, '.wpbdp-pagination')
        if not pagination:
            print("   [!] Pas de pagination trouvÃ©e, une seule page ?")
            return 1
        
        # Chercher le nombre max de pages
        page_links = self.driver.find_elements(By.CSS_SELECTOR, '.wpbdp-pagination a')
        max_page = 1
        
        for link in page_links:
            href = link.get_attribute('href') or ''
            # Extraire le numÃ©ro de page de l'URL
            match = re.search(r'/page/(\d+)/', href)
            if match:
                page_num = int(match.group(1))
                if page_num > max_page:
                    max_page = page_num
            
            # Ou depuis le texte du lien
            text = link.text.strip()
            if text.isdigit():
                page_num = int(text)
                if page_num > max_page:
                    max_page = page_num
        
        # VÃ©rifier s'il y a un lien "Dernier" ou ">>"
        last_link = self.driver.find_elements(By.CSS_SELECTOR, '.wpbdp-pagination a.last, .wpbdp-pagination a:last-child')
        if last_link:
            href = last_link[-1].get_attribute('href') or ''
            match = re.search(r'/page/(\d+)/', href)
            if match:
                max_page = int(match.group(1))
        
        print(f"   [âœ“] {max_page} pages dÃ©tectÃ©es")
        return max_page
    
    def extract_all(self):
        """Extraction complÃ¨te de tous les avocats"""
        print("=" * 60)
        print("ğŸš€ EXTRACTION ULTIME - BARREAU DE THONON")
        print("=" * 60)
        print(f"â° DÃ©but: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # 1. Trouver le nombre total de pages
        total_pages = self.find_total_pages()
        
        # 2. Limiter Ã  un maximum raisonnable
        max_pages_to_check = min(total_pages + 5, 30)  # Check quelques pages de plus au cas oÃ¹
        
        print(f"\nğŸ“š Extraction de {max_pages_to_check} pages...")
        
        # 3. Extraire chaque page
        pages_with_content = 0
        consecutive_empty = 0
        
        for page in range(1, max_pages_to_check + 1):
            count = self.extract_page(page)
            
            if count > 0:
                pages_with_content += 1
                consecutive_empty = 0
            else:
                consecutive_empty += 1
                
                # ArrÃªter aprÃ¨s 3 pages vides consÃ©cutives
                if consecutive_empty >= 3:
                    print(f"\n[!] ArrÃªt aprÃ¨s 3 pages vides consÃ©cutives")
                    break
            
            # Petit dÃ©lai pour ne pas surcharger le serveur
            time.sleep(1)
            
            # Status toutes les 5 pages
            if page % 5 == 0:
                print(f"\nğŸ“Š Status: {len(self.lawyers)} avocats uniques trouvÃ©s jusqu'Ã  prÃ©sent")
        
        # 4. Essayer aussi sans le paramÃ¨tre wpbdp_view pour voir
        print("\nğŸ” Test de pages alternatives...")
        
        # Pages simples
        for page in range(1, 6):
            url = f"https://public.barreau-thonon.fr/lannuaire/page/{page}/"
            print(f"\nğŸ“„ Test page simple {page}")
            print(f"   URL: {url}")
            
            self.driver.get(url)
            time.sleep(2)
            
            listings = self.driver.find_elements(By.CSS_SELECTOR, '.wpbdp-listing, article.listing, .lawyer-item')
            if listings:
                print(f"   [âœ“] {len(listings)} Ã©lÃ©ments trouvÃ©s")
                for listing in listings:
                    lawyer = self.extract_lawyer_from_listing(listing)
                    if lawyer and lawyer['name']:
                        key = lawyer['name'].lower().replace(' ', '_')
                        if key not in self.lawyers:
                            self.lawyers[key] = lawyer
                            print(f"      + {lawyer['name']}")
        
        print("\n" + "=" * 60)
        print("âœ… EXTRACTION TERMINÃ‰E")
        print(f"ğŸ“Š TOTAL: {len(self.lawyers)} avocats uniques extraits")
        print(f"ğŸ“„ Pages avec contenu: {pages_with_content}")
        print(f"â° Fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
    
    def save_results(self):
        """Sauvegarde les rÃ©sultats dans diffÃ©rents formats"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON
        json_file = f"thonon_final_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(list(self.lawyers.values()), f, indent=2, ensure_ascii=False)
        print(f"\nğŸ“ JSON: {json_file}")
        
        # CSV
        csv_file = f"thonon_final_{timestamp}.csv"
        with open(csv_file, 'w', newline='', encoding='utf-8') as f:
            if self.lawyers:
                fieldnames = ['name', 'address', 'phone', 'fax', 'email', 'specialities']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                for lawyer in self.lawyers.values():
                    row = {k: lawyer.get(k, '') for k in fieldnames}
                    if isinstance(row['specialities'], list):
                        row['specialities'] = ', '.join(row['specialities'])
                    writer.writerow(row)
        print(f"ğŸ“ CSV: {csv_file}")
        
        # Rapport dÃ©taillÃ©
        report_file = f"thonon_report_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("RAPPORT FINAL - BARREAU DE THONON\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total avocats: {len(self.lawyers)}\n")
            f.write(f"Objectif: ~160 avocats\n")
            
            if len(self.lawyers) >= 150:
                f.write("âœ… OBJECTIF ATTEINT!\n\n")
            else:
                f.write(f"âŒ Objectif manquÃ© de {160 - len(self.lawyers)} avocats\n\n")
            
            # Statistiques
            with_email = sum(1 for l in self.lawyers.values() if l.get('email'))
            with_phone = sum(1 for l in self.lawyers.values() if l.get('phone'))
            with_address = sum(1 for l in self.lawyers.values() if l.get('address'))
            
            f.write("STATISTIQUES:\n")
            f.write(f"  - Avec email: {with_email} ({with_email*100//len(self.lawyers)}%)\n")
            f.write(f"  - Avec tÃ©lÃ©phone: {with_phone} ({with_phone*100//len(self.lawyers)}%)\n")
            f.write(f"  - Avec adresse: {with_address} ({with_address*100//len(self.lawyers)}%)\n\n")
            
            # Liste complÃ¨te
            f.write("=" * 60 + "\n")
            f.write("LISTE COMPLÃˆTE DES AVOCATS:\n")
            f.write("=" * 60 + "\n\n")
            
            for i, (key, lawyer) in enumerate(self.lawyers.items(), 1):
                f.write(f"{i}. {lawyer.get('name', 'Sans nom')}\n")
                if lawyer.get('address'):
                    f.write(f"   ğŸ“ {lawyer['address']}\n")
                if lawyer.get('phone'):
                    f.write(f"   â˜ï¸  {lawyer['phone']}\n")
                if lawyer.get('email'):
                    f.write(f"   âœ‰ï¸  {lawyer['email']}\n")
                if lawyer.get('specialities'):
                    specs = ', '.join(lawyer['specialities']) if isinstance(lawyer['specialities'], list) else lawyer['specialities']
                    f.write(f"   ğŸ“š {specs}\n")
                f.write("\n")
        
        print(f"ğŸ“ Rapport: {report_file}")
    
    def close(self):
        """Ferme le navigateur"""
        self.driver.quit()

def main():
    """Fonction principale"""
    scraper = ThononUltimateScraper()
    
    try:
        # Extraction
        scraper.extract_all()
        
        # Sauvegarde
        scraper.save_results()
        
        # RÃ©sumÃ© final
        print("\n" + "ğŸ¯" * 30)
        print(f"\nğŸ† RÃ‰SULTAT FINAL: {len(scraper.lawyers)} avocats")
        
        if len(scraper.lawyers) >= 150:
            print("âœ… SUCCÃˆS! Objectif de ~160 avocats atteint!")
        elif len(scraper.lawyers) >= 100:
            print("âš ï¸ RÃ©sultat partiel - Plus de 100 avocats trouvÃ©s")
        else:
            print("âŒ RÃ©sultat insuffisant - Moins de 100 avocats")
            
        print("\nğŸ’¡ ANALYSE DU PROBLÃˆME:")
        if len(scraper.lawyers) < 160:
            print("Le site semble avoir des limitations:")
            print("1. Pagination limitÃ©e ou non fonctionnelle")
            print("2. Filtres gÃ©ographiques non accessibles via URL")
            print("3. Possible nÃ©cessitÃ© d'authentification")
            print("4. Les zones LÃ©man et Genevois peuvent Ãªtre sur d'autres sites")
        
        print("\n" + "ğŸ¯" * 30)
        
    except Exception as e:
        print(f"\nâŒ ERREUR: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        scraper.close()

if __name__ == "__main__":
    main()