#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SCRAPER COMPLET - BARREAU DE RENNES
===================================

Script pour extraire tous les avocats du barreau de Rennes avec leurs d√©tails complets.
URL: https://www.ordre-avocats-rennes.fr/annuaire

√âTAPES D'UTILISATION:
1. Lancer d'abord: python3 rennes_liste_complete.py (r√©cup√®re la liste de tous les avocats)
2. Puis lancer: python3 rennes_extraction_details.py (extrait les d√©tails de chaque avocat)

R√âSULTAT ATTENDU: ~1107 avocats avec emails, t√©l√©phones, adresses, sp√©cialisations
"""

import time
import csv
import json
import random
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import re
import glob

def setup_driver():
    """Configure le driver Chrome en mode headless"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    driver = webdriver.Chrome(options=chrome_options)
    return driver

def accept_cookies(driver):
    """G√®re l'acceptation des cookies"""
    try:
        print("üç™ Tentative d'acceptation des cookies...")
        time.sleep(3)
        
        cookie_selectors = [
            "#axeptio_btn_acceptAll",
            "button[data-axeptio-cookie='all']",
            "button.axeptio-button--accept-all"
        ]
        
        for selector in cookie_selectors:
            try:
                cookie_btn = WebDriverWait(driver, 5).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                )
                cookie_btn.click()
                print("‚úÖ Cookies accept√©s")
                time.sleep(2)
                return True
            except TimeoutException:
                continue
        
        print("‚ö†Ô∏è Pas de cookies √† accepter")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur cookies: {e}")
        return False

def get_total_pages(driver):
    """D√©termine le nombre total de pages (0-36 = 37 pages)"""
    try:
        driver.get("https://www.ordre-avocats-rennes.fr/annuaire")
        time.sleep(3)
        
        # Chercher le lien "Derni√®re page"
        last_page_links = driver.find_elements(By.CSS_SELECTOR, "a[title*='aller √† la derni√®re page'], a[href*='page=36'], .pager-last a")
        
        for link in last_page_links:
            href = link.get_attribute('href')
            if 'page=' in href:
                page_num = href.split('page=')[-1]
                try:
                    max_page = int(page_num)
                    total_pages = max_page + 1  # page 0-36 = 37 pages
                    print(f"üìÑ {total_pages} pages d√©tect√©es (pages 0-{max_page})")
                    return total_pages
                except ValueError:
                    continue
        
        print("üìÑ 37 pages par d√©faut (1107 avocats)")
        return 37
        
    except Exception as e:
        print(f"‚ùå Erreur calcul pages: {e}")
        return 37

def navigate_to_page(driver, page_num):
    """Navigue vers une page sp√©cifique"""
    try:
        url_page = page_num - 1  # page 1 = page=0
        
        if page_num == 1:
            url = "https://www.ordre-avocats-rennes.fr/annuaire"
        else:
            url = f"https://www.ordre-avocats-rennes.fr/annuaire?page={url_page}"
        
        print(f"üåê Page {page_num}: {url}")
        driver.get(url)
        time.sleep(random.uniform(3, 5))
        
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        time.sleep(2)
        
        lawyer_links = driver.find_elements(By.CSS_SELECTOR, "a[href*='/avocat-']")
        
        if lawyer_links:
            print(f"  ‚úÖ Page {page_num} charg√©e avec {len(lawyer_links)} liens")
            return True
        else:
            print(f"  ‚ö†Ô∏è Page {page_num} sans liens d'avocats")
            return False
        
    except Exception as e:
        print(f"‚ùå Erreur navigation page {page_num}: {e}")
        return False

def extract_lawyers_from_page(driver, page_num):
    """Extrait SEULEMENT les noms et liens des avocats (pas les d√©tails)"""
    lawyers = []
    
    try:
        lawyer_links = driver.find_elements(By.CSS_SELECTOR, "a[href*='/avocat-']")
        
        # D√©duplication par URL
        unique_links = {}
        for link in lawyer_links:
            href = link.get_attribute('href')
            if href and href not in unique_links:
                unique_links[href] = link
        
        print(f"  üìã {len(unique_links)} avocats uniques trouv√©s")
        
        for i, (href, link) in enumerate(unique_links.items()):
            try:
                raw_name = link.text.strip()
                
                if not raw_name or len(raw_name) < 3:
                    if '/avocat-' in href:
                        name_from_url = href.split('/avocat-')[-1]
                        name_parts = name_from_url.replace('-', ' ').title().split()
                        if len(name_parts) >= 2:
                            raw_name = f"Me {' '.join(name_parts)}"
                
                if not raw_name:
                    print(f"    ‚ö†Ô∏è Nom vide pour {href}")
                    continue
                
                lawyer_info = {
                    'page': page_num,
                    'nom_brut': raw_name,
                    'lien_detail': href if href.startswith('http') else f"https://www.ordre-avocats-rennes.fr{href}",
                    'index_page': i + 1
                }
                
                lawyers.append(lawyer_info)
                
            except Exception as e:
                print(f"    ‚ùå Erreur avocat {i+1} sur page {page_num}: {e}")
                continue
                
    except Exception as e:
        print(f"‚ùå Erreur extraction page {page_num}: {e}")
    
    return lawyers

def save_complete_list(all_lawyers):
    """Sauvegarde la liste compl√®te"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    json_filename = f"RENNES_LISTE_COMPLETE_{len(all_lawyers)}_avocats_{timestamp}.json"
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(all_lawyers, f, ensure_ascii=False, indent=2)
    
    csv_filename = f"RENNES_LISTE_COMPLETE_{len(all_lawyers)}_avocats_{timestamp}.csv"
    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
        if all_lawyers:
            fieldnames = ['page', 'nom_brut', 'lien_detail', 'index_page']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_lawyers)
    
    return json_filename, csv_filename

def main():
    print("üöÄ EXTRACTION LISTE COMPL√àTE - BARREAU DE RENNES")
    print("=" * 70)
    print("R√©cup√©ration de tous les 1107 avocats (√©tape 1/2)")
    print("=" * 70)
    
    driver = None
    all_lawyers = []
    
    try:
        driver = setup_driver()
        
        driver.get("https://www.ordre-avocats-rennes.fr/annuaire")
        accept_cookies(driver)
        
        total_pages = get_total_pages(driver)
        print(f"üìÑ {total_pages} pages √† traiter")
        
        # Parcourir TOUTES les pages
        for page_num in range(1, total_pages + 1):
            print(f"\nüìÑ PAGE {page_num}/{total_pages}")
            
            if not navigate_to_page(driver, page_num):
                continue
            
            page_lawyers = extract_lawyers_from_page(driver, page_num)
            if not page_lawyers:
                continue
            
            all_lawyers.extend(page_lawyers)
            print(f"  üìä Total actuel: {len(all_lawyers)} avocats")
            
            time.sleep(random.uniform(1, 3))
        
        # Sauvegarde finale
        if all_lawyers:
            json_file, csv_file = save_complete_list(all_lawyers)
            
            print(f"\nüéâ LISTE COMPL√àTE R√âCUP√âR√âE!")
            print(f"  ‚úÖ Total: {len(all_lawyers)} avocats")
            print(f"  üìÅ JSON: {json_file}")
            print(f"  üìÅ CSV: {csv_file}")
            print(f"\n‚û°Ô∏è  √âTAPE SUIVANTE: Lancez rennes_extraction_details.py")
        else:
            print("‚ùå Aucun avocat trouv√©!")
            
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        
    finally:
        if driver:
            driver.quit()

if __name__ == "__main__":
    main()