#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Scraper COMPLET pour tous les avocats du Barreau de Charente
Version production basÃ©e sur le test validÃ© Ã  100%
"""

import time
import json
import csv
import re
import html
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CharenteCompletScraper:
    def __init__(self, headless=True):
        self.base_url = "https://www.avocats-charente.com/annuaire-des-avocats"
        self.headless = headless
        self.driver = None
        self.lawyers_data = []
        self.total_pages = 9  # 132 avocats rÃ©partis sur 9 pages
        
    def setup_driver(self):
        """Configuration du driver Chrome"""
        options = Options()
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        if self.headless:
            options.add_argument('--headless')
        
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        
        try:
            self.driver = webdriver.Chrome(options=options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            logger.info("Driver Chrome configurÃ© avec succÃ¨s")
        except Exception as e:
            logger.error(f"Erreur lors de la configuration du driver: {e}")
            raise
    
    def accept_cookies(self):
        """Accepter les cookies"""
        try:
            time.sleep(3)
            buttons = self.driver.find_elements(By.TAG_NAME, "button")
            for button in buttons:
                try:
                    button_text = button.text.lower()
                    if any(word in button_text for word in ['accepter', 'accept', 'ok', 'continuer']):
                        if button.is_displayed() and button.is_enabled():
                            button.click()
                            time.sleep(2)
                            logger.info("Cookies acceptÃ©s")
                            return True
                except Exception:
                    continue
            return False
        except Exception as e:
            logger.error(f"Erreur cookies: {e}")
            return False
    
    def navigate_to_page(self, page_num):
        """Naviguer vers une page spÃ©cifique"""
        try:
            if page_num == 1:
                self.driver.get(self.base_url)
            else:
                page_url = f"{self.base_url}?limitstart={(page_num-1)*15}"
                self.driver.get(page_url)
            
            time.sleep(5)
            
            if page_num == 1:
                self.accept_cookies()
                time.sleep(3)
            
            logger.info(f"NaviguÃ© vers la page {page_num}")
            return True
            
        except Exception as e:
            logger.error(f"Erreur navigation page {page_num}: {e}")
            return False
    
    def collect_basic_info_from_page(self, page_num):
        """Collecter les infos de base d'une page"""
        try:
            logger.info(f"=== COLLECTE PAGE {page_num} ===")
            
            # Naviguer vers la page
            if not self.navigate_to_page(page_num):
                return []
            
            # Extraire les cartes des avocats
            cards = self.driver.find_elements(By.CSS_SELECTOR, ".cbUserListRow")
            
            if not cards:
                logger.warning(f"Aucune carte d'avocat trouvÃ©e page {page_num}")
                return []
            
            logger.info(f"TrouvÃ© {len(cards)} avocats sur la page {page_num}")
            
            # Collecter les infos de base
            lawyers_basic = []
            for i, card in enumerate(cards):
                try:
                    lawyer_data = {}
                    
                    # PrÃ©nom et nom
                    col1 = card.find_element(By.CSS_SELECTOR, ".cbUserListRowCol1")
                    prenom_element = col1.find_element(By.CSS_SELECTOR, ".cbUserListFC_firstname a")
                    nom_element = col1.find_element(By.CSS_SELECTOR, ".cbUserListFC_lastname a")
                    
                    lawyer_data['prenom'] = prenom_element.text.strip()
                    lawyer_data['nom'] = nom_element.text.strip()
                    lawyer_data['nom_complet'] = f"{lawyer_data['prenom']} {lawyer_data['nom']}"
                    lawyer_data['url_profil'] = prenom_element.get_attribute('href')
                    
                    # Adresse
                    col2 = card.find_element(By.CSS_SELECTOR, ".cbUserListRowCol2")
                    try:
                        lawyer_data['code_postal'] = col2.find_element(By.CSS_SELECTOR, ".cbUserListFC_cb_codepostal").text.strip()
                    except:
                        lawyer_data['code_postal'] = ''
                    
                    try:
                        lawyer_data['ville'] = col2.find_element(By.CSS_SELECTOR, ".cbUserListFC_cb_ville").text.strip()
                    except:
                        lawyer_data['ville'] = ''
                    
                    try:
                        lawyer_data['adresse'] = col2.find_element(By.CSS_SELECTOR, ".cbUserListFC_cb_adresse1").text.strip()
                    except:
                        lawyer_data['adresse'] = ''
                    
                    # TÃ©lÃ©phone
                    col3 = card.find_element(By.CSS_SELECTOR, ".cbUserListRowCol3")
                    try:
                        lawyer_data['telephone'] = col3.find_element(By.CSS_SELECTOR, ".cbUserListFC_cb_telephone").text.strip()
                    except:
                        lawyer_data['telephone'] = ''
                    
                    # SpÃ©cialitÃ©s
                    col4 = card.find_element(By.CSS_SELECTOR, ".cbUserListRowCol4")
                    lawyer_data['specialites'] = col4.text.strip()
                    
                    lawyers_basic.append(lawyer_data)
                    logger.info(f"Page {page_num} - Avocat {i+1}/{len(cards)}: {lawyer_data['nom_complet']}")
                    
                except Exception as e:
                    logger.error(f"Erreur extraction avocat {i+1} page {page_num}: {e}")
                    continue
            
            logger.info(f"Page {page_num} - CollectÃ© {len(lawyers_basic)} avocats")
            return lawyers_basic
            
        except Exception as e:
            logger.error(f"Erreur collecte page {page_num}: {e}")
            return []
    
    def extract_all_emails_from_profile(self, profile_url, lawyer_name):
        """Extraire TOUS les emails d'une page de profil - mÃ©thode validÃ©e"""
        try:
            # Aller sur la page de profil
            self.driver.get(profile_url)
            time.sleep(4)
            
            emails_found = []
            
            # MÃ©thode 1: Liens mailto directs
            mailto_links = self.driver.find_elements(By.CSS_SELECTOR, "a[href^='mailto:']")
            for link in mailto_links:
                href = link.get_attribute('href')
                email = href.replace('mailto:', '').strip()
                if email and email not in emails_found:
                    emails_found.append(email)
            
            # MÃ©thode 2: Analyse du code source pour dÃ©obfuscation
            page_source = self.driver.page_source
            
            # Pattern pour emails obfusquÃ©s dans le JavaScript
            js_email_patterns = [
                r"var\s+addy\d*\s*=\s*['\"]([^'\"]+)['\"]",
                r"addy\d*\s*=\s*['\"]([^'\"]+)['\"]",
                r"['\"]([a-zA-Z0-9._%+-]*@[a-zA-Z0-9.-]*)['\"]",
            ]
            
            for pattern in js_email_patterns:
                matches = re.findall(pattern, page_source, re.IGNORECASE)
                for match in matches:
                    # DÃ©obfusquer les entitÃ©s HTML
                    decoded_email = html.unescape(match)
                    # VÃ©rifier si c'est un email valide
                    if re.match(r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", decoded_email):
                        if decoded_email not in emails_found:
                            emails_found.append(decoded_email)
            
            # MÃ©thode 3: Recherche dans le texte visible (aprÃ¨s JavaScript)
            try:
                WebDriverWait(self.driver, 10).until(
                    lambda d: d.execute_script("return document.readyState") == "complete"
                )
                time.sleep(2)
                
                # Chercher tous les Ã©lÃ©ments contenant @
                elements_with_at = self.driver.find_elements(By.XPATH, "//*[contains(text(), '@')]")
                for elem in elements_with_at:
                    text = elem.text.strip()
                    email_matches = re.findall(r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", text)
                    for email in email_matches:
                        if email not in emails_found:
                            emails_found.append(email)
                            
            except Exception as e:
                logger.warning(f"Erreur recherche texte visible: {e}")
            
            # MÃ©thode 4: Ã‰lÃ©ments cloak
            try:
                cloak_elements = self.driver.find_elements(By.CSS_SELECTOR, "[id*='cloak']")
                for elem in cloak_elements:
                    try:
                        self.driver.execute_script("arguments[0].click();", elem)
                        time.sleep(1)
                        text = elem.text.strip()
                        email_matches = re.findall(r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", text)
                        for email in email_matches:
                            if email not in emails_found:
                                emails_found.append(email)
                    except:
                        pass
            except Exception as e:
                logger.warning(f"Erreur Ã©lÃ©ments cloak: {e}")
            
            # MÃ©thode 5: Regex avancÃ©e sur le code source
            advanced_patterns = [
                r"([a-zA-Z0-9][a-zA-Z0-9._%+-]*@[a-zA-Z0-9][a-zA-Z0-9.-]*\.[a-zA-Z]{2,})",
                r"([a-zA-Z0-9._%+-]+\s*@\s*[a-zA-Z0-9.-]+\s*\.\s*[a-zA-Z]{2,})",
            ]
            
            for pattern in advanced_patterns:
                matches = re.findall(pattern, page_source, re.IGNORECASE)
                for email in matches:
                    email = re.sub(r'\s+', '', email)
                    if email and email not in emails_found:
                        emails_found.append(email)
            
            # Filtrer et nettoyer
            valid_emails = []
            for email in emails_found:
                email = email.strip().lower()
                if (email and 
                    '@' in email and 
                    '.' in email and 
                    not email.startswith('noreply') and
                    not email.startswith('no-reply') and
                    not 'example' in email and
                    not 'test' in email and
                    len(email) > 5):
                    valid_emails.append(email)
            
            # Supprimer les doublons
            final_emails = []
            for email in valid_emails:
                if email not in final_emails:
                    final_emails.append(email)
            
            return final_emails
            
        except Exception as e:
            logger.error(f"Erreur extraction emails pour {lawyer_name}: {e}")
            return []
    
    def scrape_all_lawyers(self):
        """Scraper complet de tous les avocats"""
        try:
            logger.info("=== DÃ‰BUT SCRAPING COMPLET - 132 AVOCATS ===")
            
            # Ã‰tape 1: Collecter toutes les infos de base page par page
            all_lawyers_basic = []
            
            for page in range(1, self.total_pages + 1):
                logger.info(f"\n=== TRAITEMENT PAGE {page}/{self.total_pages} ===")
                
                page_lawyers = self.collect_basic_info_from_page(page)
                if page_lawyers:
                    all_lawyers_basic.extend(page_lawyers)
                    logger.info(f"Page {page} terminÃ©e: {len(page_lawyers)} avocats collectÃ©s")
                    
                    # Sauvegarde intermÃ©diaire
                    if page % 3 == 0:  # Toutes les 3 pages
                        self.save_intermediate_backup(all_lawyers_basic, f"partial_p{page}")
                else:
                    logger.warning(f"Aucun avocat collectÃ© page {page}")
                
                # DÃ©lai entre les pages
                time.sleep(3)
            
            logger.info(f"=== COLLECTE TERMINÃ‰E: {len(all_lawyers_basic)} AVOCATS ===")
            
            # Ã‰tape 2: Enrichir avec les emails
            logger.info(f"\n=== EXTRACTION DES EMAILS ===")
            
            for i, lawyer in enumerate(all_lawyers_basic):
                try:
                    logger.info(f"\n--- Avocat {i+1}/{len(all_lawyers_basic)}: {lawyer['nom_complet']} ---")
                    
                    if lawyer.get('url_profil'):
                        emails = self.extract_all_emails_from_profile(lawyer['url_profil'], lawyer['nom_complet'])
                        
                        # SÃ©parer les types d'emails
                        email_personnel = ''
                        email_generique = ''
                        autres_emails = []
                        
                        for email in emails:
                            if 'avocats-charente.com' in email:
                                email_generique = email
                            elif email:
                                if not email_personnel:
                                    email_personnel = email
                                else:
                                    autres_emails.append(email)
                        
                        lawyer['email_personnel'] = email_personnel
                        lawyer['email_generique'] = email_generique  
                        lawyer['autres_emails'] = ', '.join(autres_emails) if autres_emails else ''
                        lawyer['total_emails_trouves'] = len(emails)
                        
                        # Log des rÃ©sultats
                        if email_personnel:
                            logger.info(f"  âœ“ Email personnel: {email_personnel}")
                        else:
                            logger.info(f"  âœ— Aucun email personnel trouvÃ©")
                        
                        if email_generique:
                            logger.info(f"  âœ“ Email gÃ©nÃ©rique: {email_generique}")
                        
                    else:
                        logger.warning(f"  âœ— Pas d'URL de profil pour {lawyer['nom_complet']}")
                        lawyer['email_personnel'] = ''
                        lawyer['email_generique'] = ''
                        lawyer['autres_emails'] = ''
                        lawyer['total_emails_trouves'] = 0
                    
                    self.lawyers_data.append(lawyer)
                    
                    # Sauvegarde intermÃ©diaire tous les 25 avocats
                    if (i + 1) % 25 == 0:
                        self.save_intermediate_backup(self.lawyers_data, f"partial_{i+1}")
                    
                    # DÃ©lai respectueux
                    time.sleep(2)
                    
                except Exception as e:
                    logger.error(f"Erreur traitement avocat {i+1} ({lawyer.get('nom_complet', 'Inconnu')}): {e}")
                    continue
            
            return self.lawyers_data
            
        except Exception as e:
            logger.error(f"Erreur scraping complet: {e}")
            return self.lawyers_data
    
    def save_intermediate_backup(self, data, suffix):
        """Sauvegarder une copie intermÃ©diaire"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"charente_{suffix}_{timestamp}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info(f"Sauvegarde intermÃ©diaire: {filename}")
        except Exception as e:
            logger.error(f"Erreur sauvegarde intermÃ©diaire: {e}")
    
    def save_final_results(self):
        """Sauvegarder les rÃ©sultats finaux"""
        if not self.lawyers_data:
            logger.error("Aucune donnÃ©e Ã  sauvegarder")
            return None
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON
        json_filename = f"charente_COMPLET_{timestamp}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(self.lawyers_data, f, ensure_ascii=False, indent=2)
        
        # CSV
        csv_filename = f"charente_COMPLET_{timestamp}.csv"
        if self.lawyers_data:
            fieldnames = self.lawyers_data[0].keys()
            with open(csv_filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(self.lawyers_data)
        
        # CSV emails seulement
        emails_csv = f"charente_EMAILS_COMPLET_{timestamp}.csv"
        with open(emails_csv, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['email_personnel', 'nom_complet', 'ville', 'telephone'])
            for lawyer in self.lawyers_data:
                if lawyer.get('email_personnel'):
                    writer.writerow([
                        lawyer['email_personnel'], 
                        lawyer['nom_complet'], 
                        lawyer.get('ville', ''), 
                        lawyer.get('telephone', '')
                    ])
        
        # Fichier emails uniquement (txt)
        emails_txt = f"charente_EMAILS_SEULEMENT_{timestamp}.txt"
        with open(emails_txt, 'w', encoding='utf-8') as f:
            f.write("EMAILS PERSONNELS - BARREAU DE CHARENTE\n")
            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            for lawyer in self.lawyers_data:
                if lawyer.get('email_personnel'):
                    f.write(f"{lawyer['email_personnel']} - {lawyer['nom_complet']}\n")
        
        # Rapport complet
        report_filename = f"charente_RAPPORT_COMPLET_{timestamp}.txt"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(f"RAPPORT EXTRACTION COMPLÃˆTE - BARREAU DE CHARENTE\n")
            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"=" * 60 + "\n\n")
            
            # Statistiques globales
            total = len(self.lawyers_data)
            with_personal = sum(1 for l in self.lawyers_data if l.get('email_personnel'))
            with_generic = sum(1 for l in self.lawyers_data if l.get('email_generique'))
            with_phone = sum(1 for l in self.lawyers_data if l.get('telephone'))
            
            f.write("STATISTIQUES GLOBALES:\n")
            f.write(f"- Total avocats extraits: {total}\n")
            f.write(f"- Avec email personnel: {with_personal} ({with_personal/total*100:.1f}%)\n")
            f.write(f"- Avec email gÃ©nÃ©rique: {with_generic} ({with_generic/total*100:.1f}%)\n")
            f.write(f"- Avec tÃ©lÃ©phone: {with_phone} ({with_phone/total*100:.1f}%)\n")
            f.write(f"- Taux de rÃ©ussite emails personnels: {with_personal/total*100:.1f}%\n\n")
            
            # RÃ©partition par ville
            villes = {}
            for lawyer in self.lawyers_data:
                ville = lawyer.get('ville', 'Non spÃ©cifiÃ©e')
                villes[ville] = villes.get(ville, 0) + 1
            
            f.write("RÃ‰PARTITION PAR VILLE:\n")
            for ville, count in sorted(villes.items(), key=lambda x: x[1], reverse=True):
                f.write(f"- {ville}: {count} avocats\n")
            f.write("\n")
            
            # Liste des emails personnels
            f.write("EMAILS PERSONNELS TROUVÃ‰S:\n")
            f.write("-" * 40 + "\n")
            for lawyer in self.lawyers_data:
                if lawyer.get('email_personnel'):
                    f.write(f"{lawyer['email_personnel']} - {lawyer['nom_complet']}\n")
            f.write(f"\nTotal: {with_personal} emails personnels\n")
        
        logger.info(f"RÃ©sultats finaux sauvegardÃ©s:")
        logger.info(f"  - JSON complet: {json_filename}")
        logger.info(f"  - CSV complet: {csv_filename}")
        logger.info(f"  - Emails CSV: {emails_csv}")
        logger.info(f"  - Emails TXT: {emails_txt}")
        logger.info(f"  - Rapport: {report_filename}")
        
        return {
            'json': json_filename,
            'csv': csv_filename,
            'emails_csv': emails_csv,
            'emails_txt': emails_txt,
            'report': report_filename,
            'stats': {
                'total': total,
                'emails_personnels': with_personal,
                'emails_generiques': with_generic,
                'taux_reussite': with_personal/total*100 if total > 0 else 0
            }
        }
    
    def close(self):
        if self.driver:
            self.driver.quit()

def main():
    print("=== SCRAPER PRODUCTION - BARREAU DE CHARENTE ===")
    print("Extraction complÃ¨te de tous les avocats (132 avocats sur 9 pages)")
    print("=" * 60)
    
    headless = input("Mode headless? (y/n, dÃ©faut=y): ").strip().lower() != 'n'
    
    confirm = input("Lancer l'extraction complÃ¨te? (y/n): ").strip().lower()
    if confirm != 'y':
        print("Extraction annulÃ©e.")
        return
    
    scraper = CharenteCompletScraper(headless=headless)
    
    try:
        start_time = datetime.now()
        print(f"DÃ©but de l'extraction: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        scraper.setup_driver()
        lawyers = scraper.scrape_all_lawyers()
        
        if lawyers:
            files = scraper.save_final_results()
            
            end_time = datetime.now()
            duration = end_time - start_time
            
            print(f"\n" + "="*60)
            print(f"EXTRACTION COMPLÃˆTE TERMINÃ‰E !")
            print(f"="*60)
            print(f"âœ“ DurÃ©e totale: {duration}")
            print(f"âœ“ Total avocats extraits: {files['stats']['total']}")
            print(f"âœ“ Emails personnels trouvÃ©s: {files['stats']['emails_personnels']}")
            print(f"âœ“ Emails gÃ©nÃ©riques trouvÃ©s: {files['stats']['emails_generiques']}")
            print(f"âœ“ Taux de rÃ©ussite emails personnels: {files['stats']['taux_reussite']:.1f}%")
            print(f"="*60)
            
            print(f"\nFichiers gÃ©nÃ©rÃ©s:")
            print(f"  ğŸ“„ Rapport complet: {files['report']}")
            print(f"  ğŸ“Š DonnÃ©es JSON: {files['json']}")
            print(f"  ğŸ“Š DonnÃ©es CSV: {files['csv']}")
            print(f"  ğŸ“§ Emails CSV: {files['emails_csv']}")
            print(f"  ğŸ“§ Emails TXT: {files['emails_txt']}")
            
        else:
            print("âŒ Aucun avocat extrait.")
    
    except KeyboardInterrupt:
        print("\nâš ï¸  Extraction interrompue par l'utilisateur")
    except Exception as e:
        print(f"âŒ Erreur: {e}")
    
    finally:
        scraper.close()
        print("Driver fermÃ©.")

if __name__ == "__main__":
    main()